{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":283795,"sourceType":"datasetVersion","datasetId":118250},{"sourceId":3342171,"sourceType":"datasetVersion","datasetId":2017696},{"sourceId":9225133,"sourceType":"datasetVersion","datasetId":5556126}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow==2.13.0 tensorflow-compression==2.13.0 tensorflow-probability==0.20.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-25T14:38:28.99231Z","iopub.execute_input":"2024-08-25T14:38:28.992738Z","iopub.status.idle":"2024-08-25T14:40:17.150039Z","shell.execute_reply.started":"2024-08-25T14:38:28.992698Z","shell.execute_reply":"2024-08-25T14:40:17.148734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import Libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_compression as tfc\nimport os\nimport random\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:40:17.152447Z","iopub.execute_input":"2024-08-25T14:40:17.152802Z","iopub.status.idle":"2024-08-25T14:40:23.222804Z","shell.execute_reply.started":"2024-08-25T14:40:17.152766Z","shell.execute_reply":"2024-08-25T14:40:23.221712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model","metadata":{}},{"cell_type":"code","source":"class SemViT(tf.keras.Model):\n    def __init__(self, block_types, filters, num_blocks, has_gdn=False,\n                 num_symbols=512, snrdB=10, channel='AWGN'):\n        '''\n        block_types: (list) types of each building blocks\n            'V' for ViT block, 'C' for Conv (ResNet) block\n            e.g., ['C', 'C', 'V', 'V', 'C', 'C']\n        filters: (list) output dimensions for each block\n            e.g., [256, 256, 256, 256, 256, 256]\n        num_blocks: (list) # of repetition for each block\n            e.g., [1, 1, 3, 3, 1, 1]\n        has_gdn: (bool) include GDN/IGDN?\n        num_symbols: (int) # of total complex symbols sent\n            e.g., 512 for 1/6 bandwidth ratio (512 / 32*32*3)\n        snrdB: (int) channel snr (in dB)\n        channel: (str) channel type ('Rayleigh', 'AWGN', or None)\n        '''\n        super().__init__()\n        if has_gdn:\n            gdn_func=tfc.layers.GDN()\n            igdn_func=tfc.layers.GDN(inverse=True)\n        else:\n            gdn_func=tf.keras.layers.Lambda(lambda x: x)\n            igdn_func=tf.keras.layers.Lambda(lambda x: x)\n\n        assert len(block_types) == len(filters) == len(num_blocks) == 6, \\\n               \"length of block_types, filters, num_blocks should be 6\"\n        self.encoder = SemViT_Encoder(\n            block_types[:3],\n            filters[:3],\n            num_blocks[:3],\n            num_symbols,\n            gdn_func=gdn_func\n        )\n\n        if channel == 'Rayleigh':\n            self.channel = RayleighChannel(snrdB)\n        elif channel == 'AWGN':\n            self.channel = AWGNChannel(snrdB)\n        elif channel == 'Rician':\n            self.channel = RicianChannel(snrdB, k=2)\n        else:\n            self.channel = tf.identity\n\n        self.decoder = SemViT_Decoder(\n            block_types[3:],\n            filters[3:],\n            num_blocks[3:],\n            gdn_func=igdn_func\n        )\n    \n    def call(self, x):\n        x = self.encoder(x)\n        x = self.channel(x)\n        x = self.decoder(x)\n\n        return x\n\n\nclass SemViT_Encoder(tf.keras.layers.Layer):\n    def __init__(self, block_types, filters, num_blocks,\n                 num_symbols, gdn_func=None, **kwargs):\n        super().__init__()\n        self.layers = [\n            # 32 x 32 input\n            build_blocks(0, block_types, num_blocks, filters, 32, kernel_size=9, stride=2, gdn_func=gdn_func),\n            # downsampled to 16 x 16\n            build_blocks(1, block_types, num_blocks, filters, 16, kernel_size=5, stride=2, gdn_func=gdn_func),\n            # downsampled to 8 x 8\n            build_blocks(2, block_types, num_blocks, filters, 8, kernel_size=5, gdn_func=gdn_func),\n            # to constellation\n            tf.keras.layers.Conv2D(\n                filters=num_symbols // 8 // 8 * 2,\n                # current spatial dimension is 8 x 8\n                # and 2 for iq dimension\n                kernel_size=1\n            )\n        ]\n\n\n    def call(self, x):\n        for sublayer in self.layers:\n            x = sublayer(x)\n        \n        b, h, w, c = x.shape\n        x = tf.reshape(x, (-1, h*w*c//2, 2))\n        return x\n    \n\n    def get_config(self):\n        config = super().get_config()\n        return config\n\n\nclass SemViT_Decoder(tf.keras.layers.Layer):\n    def __init__(self, block_types, filters, num_blocks, gdn_func=None, **kwargs):\n        super().__init__()\n        self.layers = [\n            # 8 x 8 input\n            build_blocks(0, block_types, num_blocks, filters, 8, kernel_size=5, gdn_func=gdn_func),\n            # upsampled to 16 x 16\n            tf.keras.layers.Resizing(16, 16),\n            build_blocks(1, block_types, num_blocks, filters, 16, kernel_size=5, gdn_func=gdn_func),\n            # upsampled to 32 x 32\n            tf.keras.layers.Resizing(32, 32),\n            build_blocks(2, block_types, num_blocks, filters, 32, kernel_size=9, gdn_func=gdn_func),\n            # to image\n            tf.keras.layers.Conv2D(\n                filters=3,\n                kernel_size=1,\n                activation='sigmoid'\n            )\n        ]\n\n\n    def call(self, x):\n        b, c, _ = x.shape\n        x = tf.reshape(x, (-1, 8, 8, c*2//64))\n\n        for sublayer in self.layers:\n            x = sublayer(x)\n        return x\n    \n\n    def get_config(self):\n        config = super().get_config()\n        return config\n\n\ndef build_blocks(layer_idx, block_types, num_blocks, filters, spatial_size, kernel_size=5, stride=1, gdn_func=None):\n    assert block_types[layer_idx] in ('C', 'V'), \"layer type should be either C or V\"\n\n    if block_types[layer_idx] == 'C':\n        return build_conv(\n            repetition=num_blocks[layer_idx],\n            filter_size=filters[layer_idx],\n            kernel_size=kernel_size,\n            stride=stride,\n            gdn_func=gdn_func)\n    else:\n        return build_vitblocks(\n            repetition=num_blocks[layer_idx],\n            num_heads=filters[layer_idx]//32,\n            head_size=32,\n            spatial_size=spatial_size,\n            stride=stride,\n            gdn_func=gdn_func)\n\n\ndef build_conv(repetition, filter_size, kernel_size=5, stride=1, gdn_func=None):\n    x = tf.keras.Sequential()\n    for i in range(repetition):\n        s = stride if i == 0 else 1\n        x.add(tfc.SignalConv2D(\n                filter_size,\n                kernel_size,\n                corr=True,\n                strides_down=s,\n                padding=\"same_zeros\",\n                use_bias=True,\n        ))\n        if gdn_func:\n            x.add(gdn_func)\n        x.add(tf.keras.layers.PReLU(shared_axes=[1, 2]))\n    return x\n\n\ndef build_vitblocks(repetition, num_heads, head_size, spatial_size, stride=1, gdn_func=None):\n    x = tf.keras.Sequential()\n    for i in range(repetition):\n        s = stride if i == 0 else 1\n        x.add(VitBlock(num_heads, head_size, spatial_size, stride=s))\n        if gdn_func:\n            x.add(gdn_func)\n    return x\n\n\nclass SemViT_Encoder_Only(tf.keras.Model):\n    def __init__(self, block_types, filters, num_blocks, has_gdn=False,\n                 num_symbols=512):\n        super().__init__()\n        if has_gdn:\n            gdn_func=tfc.layers.GDN()\n            igdn_func=tfc.layers.GDN(inverse=True)\n        else:\n            gdn_func=tf.keras.layers.Lambda(lambda x: x)\n            igdn_func=tf.keras.layers.Lambda(lambda x: x)\n\n        assert len(block_types) == len(filters) == len(num_blocks) == 6, \\\n               \"length of block_types, filters, num_blocks should be 6\"\n        self.encoder = SemViT_Encoder(\n            block_types[:3],\n            filters[:3],\n            num_blocks[:3],\n            num_symbols,\n            gdn_func=gdn_func\n        )\n    \n    def call(self, x):\n        x = self.encoder(x)\n\n        return x\n\n\nclass SemViT_Decoder_Only(tf.keras.Model):\n    def __init__(self, block_types, filters, num_blocks, has_gdn=False,\n                 num_symbols=512):\n        super().__init__()\n        if has_gdn:\n            gdn_func=tfc.layers.GDN()\n            igdn_func=tfc.layers.GDN(inverse=True)\n        else:\n            gdn_func=tf.keras.layers.Lambda(lambda x: x)\n            igdn_func=tf.keras.layers.Lambda(lambda x: x)\n\n        assert len(block_types) == len(filters) == len(num_blocks) == 6, \\\n               \"length of block_types, filters, num_blocks should be 6\"\n        self.decoder = SemViT_Decoder(\n            block_types[3:],\n            filters[3:],\n            num_blocks[3:],\n            gdn_func=igdn_func\n        )\n    \n    def call(self, x):\n        x = self.decoder(x)\n\n        return x\n\nclass Channel_Only(tf.keras.Model):\n    def __init__(self, snrdB=10, channel='AWGN'):\n        super().__init__()\n        if channel == 'Rayleigh':\n            self.channel = RayleighChannel(snrdB)\n        elif channel == 'AWGN':\n            self.channel = AWGNChannel(snrdB)\n        elif channel == 'Rician':\n            self.channel = RicianChannel(snrdB, k=2)\n        else:\n            self.channel = tf.identity\n    \n    def call(self, x):\n        x = self.channel(x)\n        return x\n\n\n\n\nclass AWGNChannel(tf.keras.layers.Layer):\n    def __init__(self, snrdB=None):\n        super().__init__()\n        self.snr = 10 ** (snrdB / 10) # in dB\n    \n\n    def call(self, x):\n        '''\n        x: inputs with shape (b, c, 2)\n           where last dimension denotes in-phase and quadrature-phase elements, respectively.\n        '''\n        assert x.shape[2] == 2, \"input shape should be (b, c, 2), where last dimension denotes i and q, respectively\"\n        assert len(x.shape) == 3, \"input shape should be (b, c, 2)\"\n\n        i = x[:,:,0]\n        q = x[:,:,1]\n\n        # power normalization\n        sig_power = tf.math.reduce_mean(i ** 2 + q ** 2)\n        snr = self.snr\n\n        n = tf.random.normal(\n            tf.shape(x),\n            mean=0,\n            stddev=tf.math.sqrt(sig_power/(2*snr))\n        )\n\n        y = x + n\n        return y\n    \n\n    def get_config(self):\n        config = super().get_config()\n        return config\n\n\n\nclass RayleighChannel(tf.keras.layers.Layer):\n    def __init__(self, snrdB=None, clip_snrdB=5):\n        super().__init__()\n        self.snr = 10 ** (snrdB / 10) # in dB\n        self.clip_snr = 10 ** (clip_snrdB / 10)\n    \n\n    def call(self, x):\n        '''\n        x: inputs with shape (b, c, 2)\n           where last dimension denotes in-phase and quadrature-phase elements, respectively.\n        Assumes slow rayleigh fading, where h does not change for single batch data\n\n        We clip the coefficient h to generate short-term SNR between +-5 dB of given long-term SNR.\n        '''\n        assert x.shape[2] == 2, \"input shape should be (b, c, 2), where last dimension denotes i and q, respectively\"\n        assert len(x.shape) == 3, \"input shape should be (b, c, 2)\"\n        \n        i = x[:,:,0]\n        q = x[:,:,1]\n\n        # power normalization\n        sig_power = tf.math.reduce_mean(i ** 2 + q ** 2)\n        \n        # batch-wise slow fading\n        h = tf.random.normal(\n            (1, 1, 2),\n            mean=0,\n            stddev=tf.math.sqrt(0.5)\n        )\n\n        snr = self.snr\n\n        n = tf.random.normal(\n            tf.shape(x),\n            mean=0,\n            stddev=tf.math.sqrt(sig_power/(2*snr))\n        )\n\n        yhat = h * x + n\n\n        return yhat\n    \n\n    def get_config(self):\n        config = super().get_config()\n        return config\n\n\n\nclass RicianChannel(tf.keras.layers.Layer):\n    def __init__(self, snrdB=None, k=2):\n        super().__init__()\n        self.snr = 10 ** (snrdB / 10) # in dB\n        self.k = k\n    \n\n    def call(self, x):\n        '''\n        x: inputs with shape (b, c, 2)\n           where last dimension denotes in-phase and quadrature-phase elements, respectively.\n        Assumes slow rayleigh fading (for NLOS part), where h does not change for single batch data\n\n        We clip the coefficient h to generate short-term SNR between +-5 dB of given long-term SNR.\n        '''\n        assert x.shape[2] == 2, \"input shape should be (b, c, 2), where last dimension denotes i and q, respectively\"\n        assert len(x.shape) == 3, \"input shape should be (b, c, 2)\"\n        \n        i = x[:,:,0]\n        q = x[:,:,1]\n\n        # power normalization\n        sig_power = tf.math.reduce_mean(i ** 2 + q ** 2)\n        \n        # batch-wise slow fading\n        h = tf.random.normal(\n            (1, 1, 2),\n            mean=0,\n            stddev=tf.math.sqrt(0.5)\n        )\n\n        snr = self.snr\n\n        n = tf.random.normal(\n            tf.shape(x),\n            mean=0,\n            stddev=tf.math.sqrt(sig_power/(2*snr))\n        )\n\n        k = self.k\n\n        yhat = tf.math.sqrt(1 / (1+k)) * h * x + tf.math.sqrt(k / (1+k)) * x + n\n\n        return yhat\n    \n    \n\nclass MLP(tf.keras.layers.Layer):\n    def __init__(self, out_features, expansion_coeff=4):\n        super().__init__()\n\n        self.fc1 = tf.keras.layers.Dense(\n            out_features * expansion_coeff\n        )\n        self.gelu = tf.nn.gelu\n        self.fc2 = tf.keras.layers.Dense(\n            out_features\n        )\n    \n    def call(self, x):\n        x = self.fc1(x)\n        x = self.gelu(x)\n        x = self.fc2(x)\n        return x\n\n\nclass RelativeMHSA(tf.keras.layers.Layer):\n    '''\n    Implements multihead attention \n    with Swin-like learnable 2d relative positional encoding\n    '''\n    def __init__(self, num_heads, dim_head, spatial_size):\n        '''\n        num_heads: the number of heads\n        dim_head: channel dimensions per head\n        spatial_size: height/width of the input\n        query/key/value shape: (b, h, w, c) where h == w \n        '''\n        super().__init__()\n\n        assert num_heads != 0, \"num_heads should be nonzero\"\n\n        self.dim_head = dim_head\n        self.num_heads = num_heads\n\n        self.qkv = tf.keras.layers.Conv2D(\n            filters=dim_head * 3,\n            kernel_size=1\n        )\n\n        self.head_transform = tf.keras.layers.Conv2D(\n            filters=dim_head*num_heads,\n            kernel_size=1\n        )\n\n        # build rel. pos parameter and bias index here\n        h = spatial_size\n        pos_emb_idx_horizontal = tf.tile(tf.constant(\n            [range(i, i+h) for i in range(0, -h, -1)]),\n            multiples=[h, h]\n        )\n\n        pos_emb_idx_vertical = tf.repeat(\n            tf.repeat(\n                tf.constant([range(i, i+h)\n                             for i in range(0, -h, -1)]),\n                repeats=h,\n                axis=0\n            ),\n            repeats=h,\n            axis=-1\n        )\n\n        pos_emb_idx = (2*h-1) * (pos_emb_idx_vertical + h - 1) + \\\n                      (pos_emb_idx_horizontal + h - 1)\n\n        self.pos_emb_idx = pos_emb_idx\n\n        initializer = tf.keras.initializers.GlorotNormal()\n        self.learned_pos_emb = tf.Variable(\n            initializer(shape=((2*h-1)**2,))\n        )\n\n\n    def call(self, x):\n        b, h, w, c = x.shape\n        m = self.num_heads\n\n        assert c % m == 0, \"channel dimension should be divisible \" \\\n               f\"with number of heads, but c={c} and m={m} found\"\n        d_h = c//m\n\n        # [b, h, w, c] to [b, m, h, w, c//m]\n        x = tf.reshape(x, (-1, h, w, m, d_h))\n        x = tf.transpose(x, (0, 3, 1, 2, 4))\n\n        x = self.qkv(x)\n        x = tf.reshape(x, (-1, h*w, self.dim_head, 3))\n        q = x[:, :, :, 0]\n        k = x[:, :, :, 1]\n        v = x[:, :, :, 2]\n\n        # normalize with sqrt(d)\n        q = q / tf.sqrt(tf.constant(self.dim_head, tf.float32))\n\n        # attention map computation; q, k: (b*m, h*w, d_h)\n        att_map = tf.einsum('bic,bjc->bij', q, k)\n\n        # add rel. pos. encoding to attention map\n        pos_emb = tf.gather(self.learned_pos_emb, self.pos_emb_idx)\n\n        att_map = att_map + pos_emb\n        att_map = tf.nn.softmax(att_map)\n        \n        v = tf.reshape(v, (-1, h*w, self.dim_head))\n        v = tf.einsum('bij,bjc->bic', att_map, v)\n\n        # [b, m, h, w, c//m] to [b, h, w, c]\n        v = tf.reshape(v, (-1, m, h, w, c//m))\n        v = tf.transpose(v, (0, 2, 3, 1, 4))\n        v = tf.reshape(v, (-1, h, w, c))\n\n        v = self.head_transform(v)\n        return v\n\n\nclass VitBlock(tf.keras.layers.Layer):\n    def __init__(self, num_heads, head_size,\n                 spatial_size, stride=1):\n        '''\n        num_heads: the number of heads\n        head_size: channel dimensions per head\n        spatial_size: height/width of the input\n                      (before downsampling)\n        patchmerge: (boolean) 1/2 downsampling before MHSA\n        '''\n        super().__init__()\n\n        d_out = num_heads * head_size\n        self.ln1 = tf.keras.layers.LayerNormalization()\n\n        self.patchmerge = tf.keras.layers.Conv2D(\n            filters=d_out,\n            kernel_size=stride,\n            strides=stride,\n        )\n        spatial_size //= stride\n\n        self.mhsa = RelativeMHSA(\n            num_heads=num_heads,\n            dim_head=head_size,\n            spatial_size=spatial_size\n        )\n\n        self.ln2 = tf.keras.layers.LayerNormalization()\n        self.mlp = MLP(d_out)\n\n    def call(self, x):\n        x = self.patchmerge(x)\n        x = self.ln1(x)\n        x_residual = x\n\n        x = self.mhsa(x) \n        x = tf.add(x, x_residual)\n        \n        x_residual = x\n        x = self.ln2(x)\n        x = self.mlp(x)\n        x = tf.add(x, x_residual)\n\n        return x\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:40:23.224578Z","iopub.execute_input":"2024-08-25T14:40:23.225273Z","iopub.status.idle":"2024-08-25T14:40:23.290873Z","shell.execute_reply.started":"2024-08-25T14:40:23.225231Z","shell.execute_reply":"2024-08-25T14:40:23.289407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Run if need to train","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 64          #Change the batch size if needed\n\ndef dataset_generator(dir, mode=None, shuffle=True):\n    if mode:\n        dataset = image_dataset_from_directory(\n            directory=dir,\n            label_mode='int',\n            labels='inferred',\n            color_mode='rgb',\n            batch_size=BATCH_SIZE,\n            image_size=(32, 32),\n            shuffle=shuffle,\n            interpolation='bilinear',\n            validation_split=0.1,\n            subset=mode,\n            seed=0\n        )\n    else:\n        dataset = image_dataset_from_directory(\n            directory=dir,\n            label_mode='int',\n            labels='inferred',\n            color_mode='rgb',\n            batch_size=BATCH_SIZE,\n            image_size=(32, 32),\n            shuffle=shuffle,\n            interpolation='bilinear'\n        )\n\n    return dataset\n\n\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n\n\n\n\n\ndef prepare_dataset():\n  AUTO = tf.data.experimental.AUTOTUNE\n  test_ds = dataset_generator('/kaggle/input/cifar10-pngs-in-folders/cifar10/test/')           #Give the correct paths\n  train_ds = dataset_generator('/kaggle/input/cifar10-pngs-in-folders/cifar10/train/').cache()\n\n  normalize = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n  augment_layer = tf.keras.Sequential([\n        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n    ])\n\n  def normalize_and_augment(image, training):\n    image = augment_layer(image, training=training)\n    return image\n\n  train_ds = (\n    train_ds.shuffle(50000, reshuffle_each_iteration=True)\n            .map(lambda x, y: (normalize_and_augment(x, training=True), y), num_parallel_calls=AUTO)\n            .map(lambda x, _: (x, x))\n            .prefetch(AUTO)\n  )\n  test_ds = (\n    test_ds.map(lambda x, y: (normalize(x), y))\n           .map(lambda x, _: (x, x))\n           .cache()\n           .prefetch(AUTO)\n  )\n\n  return train_ds, test_ds\n\ndef main(config):\n    if config['gpu']:\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = config['gpu']\n\n    # Load CIFAR-10 dataset\n    train_ds, test_ds = prepare_dataset()\n\n    EXPERIMENT_NAME = config['experiment_name']\n    print(f'Running {EXPERIMENT_NAME}')\n\n    model = SemViT(\n        config['block_types'],\n        config['filters'],\n        config['repetitions'],\n        has_gdn=config['gdn'],\n        num_symbols=config['data_size'],\n        snrdB=config['train_snrdB'],\n        channel=config['channel_types']\n    )\n\n    def psnr(y_true, y_pred):\n        return tf.image.psnr(y_true, y_pred, max_val=1)\n\n    model.compile(\n        loss='mse',\n        optimizer=tf.keras.optimizers.legacy.Adam(\n            learning_rate=1e-4\n        ),\n        metrics=[\n            psnr\n        ]\n    )\n\n    model.build(input_shape=(None, 32, 32, 3))\n    model.summary()\n\n    if config['ckpt'] is not None:\n        model.load_weights(config['ckpt'])\n\n    save_ckpt = [\n        tf.keras.callbacks.ModelCheckpoint(\n            filepath=f\"./ckpt/{EXPERIMENT_NAME}_\" + f\"{config['epochs']}\",\n            save_best_only=True,\n            monitor=\"val_loss\",\n            save_weights_only=True,\n            options=tf.train.CheckpointOptions(\n                experimental_io_device=None, experimental_enable_async_checkpoint=True\n            )\n        )\n    ]\n\n    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'logs/{EXPERIMENT_NAME}')\n    history = model.fit(\n        train_ds,\n        initial_epoch=config['initial_epoch'],\n        epochs=config['epochs'],\n        callbacks=[tensorboard, save_ckpt],\n        validation_data=test_ds,\n    )\n\n    model.save_weights(f\"{EXPERIMENT_NAME}_\" + f\"{config['epochs']}\")\n    \n\nconfig = {\n    'data_size': 512,\n    'channel_types': 'AWGN',\n    'train_snrdB': 10,\n    'block_types': 'CCVVCC',\n    'experiment_name': 'experiment_1',\n    'epochs': 10,\n    'filters': [256, 256, 256, 256, 256, 256],\n    'repetitions': [1, 1, 3, 3, 1, 1],\n    'gdn': False,\n    'initial_epoch': 0,\n    'ckpt': '/kaggle/input/vit-597/CCVVCC_512_10dB_599',\n    'gpu': '0'\n}\n\n#main(config)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imBatchtoImage(batch_images):\n    '''\n    turns b, 32, 32, 3 images into single sqrt(b) * 32, sqrt(b) * 32, 3 image.\n    '''\n    batch, h, w, c = batch_images.shape\n    b = int(batch ** 0.5)\n\n    divisor = b\n    while batch % divisor != 0:\n        divisor -= 1\n    \n    image = tf.reshape(batch_images, (-1, batch//divisor, h, w, c))\n    image = tf.transpose(image, [0, 2, 1, 3, 4])\n    image = tf.reshape(image, (-1, batch//divisor*w, c))\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:40:23.293028Z","iopub.execute_input":"2024-08-25T14:40:23.293419Z","iopub.status.idle":"2024-08-25T14:40:23.310055Z","shell.execute_reply.started":"2024-08-25T14:40:23.293379Z","shell.execute_reply":"2024-08-25T14:40:23.308835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Variables","metadata":{}},{"cell_type":"code","source":"arch = 'CCVVCC'\nfilters_used = [256,256,256,256,256,256]\nrepetitions_used = [1,1,3,3,1,1]\nnum_symbols_used = 512\nhas_gdn = False\nckpt_name = '/kaggle/input/vit-597/CCVVCC_512_10dB_599'\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:40:23.311369Z","iopub.execute_input":"2024-08-25T14:40:23.311847Z","iopub.status.idle":"2024-08-25T14:40:23.329593Z","shell.execute_reply.started":"2024-08-25T14:40:23.311797Z","shell.execute_reply":"2024-08-25T14:40:23.32815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create the model","metadata":{}},{"cell_type":"code","source":"encoder_network = SemViT_Encoder_Only(arch, filters_used, repetitions_used, has_gdn=False, num_symbols=num_symbols_used)\n\ndecoder_network = SemViT_Decoder_Only(arch, filters_used, repetitions_used, has_gdn=False, num_symbols=num_symbols_used)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:40:53.909581Z","iopub.execute_input":"2024-08-25T14:40:53.910026Z","iopub.status.idle":"2024-08-25T14:40:54.153165Z","shell.execute_reply.started":"2024-08-25T14:40:53.90997Z","shell.execute_reply":"2024-08-25T14:40:54.152047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load Weights","metadata":{}},{"cell_type":"code","source":"encoder_network.load_weights(ckpt_name).expect_partial()\ndecoder_network.load_weights(ckpt_name).expect_partial()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:41:01.811488Z","iopub.execute_input":"2024-08-25T14:41:01.811899Z","iopub.status.idle":"2024-08-25T14:41:01.896922Z","shell.execute_reply.started":"2024-08-25T14:41:01.811863Z","shell.execute_reply":"2024-08-25T14:41:01.895763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CIFAR-10 image (32x32) Only for testing purposes","metadata":{}},{"cell_type":"code","source":"# image_path = '/kaggle/input/cifar10-pngs-in-folders/cifar10/test/airplane/0001.png'\n# image = Image.open(image_path).convert('RGB')\n\n# original_image = np.array(image)\n\n# # Convert to numpy array and rescale to [0, 1]\n# image = np.array(image) / 255.0\n\n# # Break the image into 32x32 patches\n# patches = tf.image.extract_patches(\n#     images=tf.expand_dims(image, axis=0),\n#     sizes=[1, 32, 32, 1],\n#     strides=[1, 32, 32, 1],\n#     rates=[1, 1, 1, 1],\n#     padding='VALID'\n# )\n\n# # Reshape patches to (batch_size, 32, 32, 3)\n# patches = tf.reshape(patches, (-1, 32, 32, 3))","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:20:24.566848Z","iopub.execute_input":"2024-08-25T15:20:24.567417Z","iopub.status.idle":"2024-08-25T15:20:24.587716Z","shell.execute_reply.started":"2024-08-25T15:20:24.567373Z","shell.execute_reply":"2024-08-25T15:20:24.58646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Give path of image (Can be any size. It will then be resized to 256x256)","metadata":{}},{"cell_type":"code","source":"image_path = '/kaggle/input/div2k-high-resolution-images/DIV2K_train_HR/DIV2K_train_HR/0037.png'\nimage = Image.open(image_path).convert('RGB')\n\n# Resize the image to 256x256 \nimage = image.resize((256, 256), Image.LANCZOS)\n\noriginal_image = np.array(image)\n\n# Convert to numpy array and rescale to [0, 1]\nimage = np.array(image) / 255.0\n\n# Break the image into 32x32 patches\npatches = tf.image.extract_patches(\n    images=tf.expand_dims(image, axis=0),\n    sizes=[1, 32, 32, 1],\n    strides=[1, 32, 32, 1],\n    rates=[1, 1, 1, 1],\n    padding='VALID'\n)\n\n# Reshape patches to (batch_size, 32, 32, 3)\npatches = tf.reshape(patches, (-1, 32, 32, 3))","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:25:34.387475Z","iopub.execute_input":"2024-08-25T15:25:34.387968Z","iopub.status.idle":"2024-08-25T15:25:34.545686Z","shell.execute_reply.started":"2024-08-25T15:25:34.387926Z","shell.execute_reply":"2024-08-25T15:25:34.544443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encoder","metadata":{}},{"cell_type":"code","source":"encoded_data = encoder_network(patches)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:25:35.426272Z","iopub.execute_input":"2024-08-25T15:25:35.426925Z","iopub.status.idle":"2024-08-25T15:25:36.296915Z","shell.execute_reply.started":"2024-08-25T15:25:35.426871Z","shell.execute_reply":"2024-08-25T15:25:36.295748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Add Channel if needed","metadata":{}},{"cell_type":"code","source":"channel_used = 'AWGN'\nsnr_used = 10\n\nchannel_model = Channel_Only(snr_used, channel_used)\ntransmitted_data = channel_model(encoded_data)\n\n#transmitted_data = encoded_data    # If not simulating channel","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:25:36.487145Z","iopub.execute_input":"2024-08-25T15:25:36.488041Z","iopub.status.idle":"2024-08-25T15:25:36.50643Z","shell.execute_reply.started":"2024-08-25T15:25:36.487993Z","shell.execute_reply":"2024-08-25T15:25:36.505375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decoder","metadata":{}},{"cell_type":"code","source":"decoded_data = decoder_network(transmitted_data)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:25:38.28615Z","iopub.execute_input":"2024-08-25T15:25:38.286595Z","iopub.status.idle":"2024-08-25T15:25:45.492458Z","shell.execute_reply.started":"2024-08-25T15:25:38.286554Z","shell.execute_reply":"2024-08-25T15:25:45.491359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reconstruct Image","metadata":{}},{"cell_type":"code","source":"reconstructed_image = imBatchtoImage(decoded_data)\n\n# Post-process reconstructed image (rescale to [0, 255])\nreconstructed_image = np.clip(reconstructed_image * 255, 0, 255).astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:25:55.636739Z","iopub.execute_input":"2024-08-25T15:25:55.637219Z","iopub.status.idle":"2024-08-25T15:25:55.657735Z","shell.execute_reply.started":"2024-08-25T15:25:55.637175Z","shell.execute_reply":"2024-08-25T15:25:55.656571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the 2 images and calculate PSNR","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.title(\"Original Image\")\nplt.imshow(original_image)\n\nplt.subplot(1, 2, 2)\nplt.title(\"Reconstructed Image\")\nplt.imshow(reconstructed_image)\nplt.show()\n\npsnr_value = tf.image.psnr(original_image, reconstructed_image, max_val=255)\nprint(f\"PSNR: {psnr_value.numpy():.2f} dB\")","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:25:56.696219Z","iopub.execute_input":"2024-08-25T15:25:56.69668Z","iopub.status.idle":"2024-08-25T15:25:57.402708Z","shell.execute_reply.started":"2024-08-25T15:25:56.696635Z","shell.execute_reply":"2024-08-25T15:25:57.401562Z"},"trusted":true},"execution_count":null,"outputs":[]}]}