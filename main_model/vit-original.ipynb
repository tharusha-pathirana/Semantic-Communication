{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-16T14:46:59.975824Z","iopub.status.busy":"2024-08-16T14:46:59.975332Z","iopub.status.idle":"2024-08-16T14:48:56.997293Z","shell.execute_reply":"2024-08-16T14:48:56.995631Z","shell.execute_reply.started":"2024-08-16T14:46:59.975754Z"},"trusted":true},"outputs":[],"source":["!pip install tensorflow==2.13.0 tensorflow-compression==2.13.0 tensorflow-probability==0.20.0"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-16T14:49:44.156194Z","iopub.status.busy":"2024-08-16T14:49:44.155684Z","iopub.status.idle":"2024-08-16T14:49:51.073360Z","shell.execute_reply":"2024-08-16T14:49:51.072159Z","shell.execute_reply.started":"2024-08-16T14:49:44.156151Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_compression as tfc\n","import os\n","import random\n","from tensorflow.keras.preprocessing import image_dataset_from_directory"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-16T14:49:53.969440Z","iopub.status.busy":"2024-08-16T14:49:53.968767Z","iopub.status.idle":"2024-08-16T14:49:54.303857Z","shell.execute_reply":"2024-08-16T14:49:54.302819Z","shell.execute_reply.started":"2024-08-16T14:49:53.969406Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 64          #Change the batch size if needed\n","\n","def dataset_generator(dir, mode=None, shuffle=True):\n","    if mode:\n","        dataset = image_dataset_from_directory(\n","            directory=dir,\n","            label_mode='int',\n","            labels='inferred',\n","            color_mode='rgb',\n","            batch_size=BATCH_SIZE,\n","            image_size=(32, 32),\n","            shuffle=shuffle,\n","            interpolation='bilinear',\n","            validation_split=0.1,\n","            subset=mode,\n","            seed=0\n","        )\n","    else:\n","        dataset = image_dataset_from_directory(\n","            directory=dir,\n","            label_mode='int',\n","            labels='inferred',\n","            color_mode='rgb',\n","            batch_size=BATCH_SIZE,\n","            image_size=(32, 32),\n","            shuffle=shuffle,\n","            interpolation='bilinear'\n","        )\n","\n","    return dataset\n","\n","\n","class SemViT(tf.keras.Model):\n","    def __init__(self, block_types, filters, num_blocks, has_gdn=True,\n","                 num_symbols=512, snrdB=25, channel='AWGN'):\n","        '''\n","        block_types: (list) types of each building blocks\n","            'V' for ViT block, 'C' for Conv (ResNet) block\n","            e.g., ['C', 'C', 'V', 'V', 'C', 'C']\n","        filters: (list) output dimensions for each block\n","            e.g., [256, 256, 256, 256, 256, 256]\n","        num_blocks: (list) # of repetition for each block\n","            e.g., [1, 1, 3, 3, 1, 1]\n","        has_gdn: (bool) include GDN/IGDN?\n","        num_symbols: (int) # of total complex symbols sent\n","            e.g., 512 for 1/6 bandwidth ratio (512 / 32*32*3)\n","        snrdB: (int) channel snr (in dB)\n","        channel: (str) channel type ('Rayleigh', 'AWGN', or None)\n","        '''\n","        super().__init__()\n","        if has_gdn:\n","            gdn_func=tfc.layers.GDN()\n","            igdn_func=tfc.layers.GDN(inverse=True)\n","        else:\n","            gdn_func=tf.keras.layers.Lambda(lambda x: x)\n","            igdn_func=tf.keras.layers.Lambda(lambda x: x)\n","\n","        assert len(block_types) == len(filters) == len(num_blocks) == 6, \\\n","               \"length of block_types, filters, num_blocks should be 6\"\n","        self.encoder = SemViT_Encoder(\n","            block_types[:3],\n","            filters[:3],\n","            num_blocks[:3],\n","            num_symbols,\n","            gdn_func=gdn_func\n","        )\n","\n","        if channel == 'Rayleigh':\n","            self.channel = RayleighChannel(snrdB)\n","        elif channel == 'AWGN':\n","            self.channel = AWGNChannel(snrdB)\n","        elif channel == 'Rician':\n","            self.channel = RicianChannel(snrdB, k=2)\n","        else:\n","            self.channel = tf.identity\n","\n","        self.decoder = SemViT_Decoder(\n","            block_types[3:],\n","            filters[3:],\n","            num_blocks[3:],\n","            gdn_func=igdn_func\n","        )\n","    \n","    def call(self, x):\n","        x = self.encoder(x)\n","        x = self.channel(x)\n","        x = self.decoder(x)\n","\n","        return x\n","\n","\n","class SemViT_Encoder(tf.keras.layers.Layer):\n","    def __init__(self, block_types, filters, num_blocks,\n","                 num_symbols, gdn_func=None, **kwargs):\n","        super().__init__()\n","        self.layers = [\n","            # 32 x 32 input\n","            build_blocks(0, block_types, num_blocks, filters, 32, kernel_size=9, stride=2, gdn_func=gdn_func),\n","            # downsampled to 16 x 16\n","            build_blocks(1, block_types, num_blocks, filters, 16, kernel_size=5, stride=2, gdn_func=gdn_func),\n","            # downsampled to 8 x 8\n","            build_blocks(2, block_types, num_blocks, filters, 8, kernel_size=5, gdn_func=gdn_func),\n","            # to constellation\n","            tf.keras.layers.Conv2D(\n","                filters=num_symbols // 8 // 8 * 2,\n","                # current spatial dimension is 8 x 8\n","                # and 2 for iq dimension\n","                kernel_size=1\n","            )\n","        ]\n","\n","\n","    def call(self, x):\n","        for sublayer in self.layers:\n","            x = sublayer(x)\n","        \n","        b, h, w, c = x.shape\n","        x = tf.reshape(x, (-1, h*w*c//2, 2))\n","        return x\n","    \n","\n","    def get_config(self):\n","        config = super().get_config()\n","        return config\n","\n","\n","class SemViT_Decoder(tf.keras.layers.Layer):\n","    def __init__(self, block_types, filters, num_blocks, gdn_func=None, **kwargs):\n","        super().__init__()\n","        self.layers = [\n","            # 8 x 8 input\n","            build_blocks(0, block_types, num_blocks, filters, 8, kernel_size=5, gdn_func=gdn_func),\n","            # upsampled to 16 x 16\n","            tf.keras.layers.Resizing(16, 16),\n","            build_blocks(1, block_types, num_blocks, filters, 16, kernel_size=5, gdn_func=gdn_func),\n","            # upsampled to 32 x 32\n","            tf.keras.layers.Resizing(32, 32),\n","            build_blocks(2, block_types, num_blocks, filters, 32, kernel_size=9, gdn_func=gdn_func),\n","            # to image\n","            tf.keras.layers.Conv2D(\n","                filters=3,\n","                kernel_size=1,\n","                activation='sigmoid'\n","            )\n","        ]\n","\n","\n","    def call(self, x):\n","        b, c, _ = x.shape\n","        x = tf.reshape(x, (-1, 8, 8, c*2//64))\n","\n","        for sublayer in self.layers:\n","            x = sublayer(x)\n","        return x\n","    \n","\n","    def get_config(self):\n","        config = super().get_config()\n","        return config\n","\n","\n","def build_blocks(layer_idx, block_types, num_blocks, filters, spatial_size, kernel_size=5, stride=1, gdn_func=None):\n","    assert block_types[layer_idx] in ('C', 'V'), \"layer type should be either C or V\"\n","\n","    if block_types[layer_idx] == 'C':\n","        return build_conv(\n","            repetition=num_blocks[layer_idx],\n","            filter_size=filters[layer_idx],\n","            kernel_size=kernel_size,\n","            stride=stride,\n","            gdn_func=gdn_func)\n","    else:\n","        return build_vitblocks(\n","            repetition=num_blocks[layer_idx],\n","            num_heads=filters[layer_idx]//32,\n","            head_size=32,\n","            spatial_size=spatial_size,\n","            stride=stride,\n","            gdn_func=gdn_func)\n","\n","\n","def build_conv(repetition, filter_size, kernel_size=5, stride=1, gdn_func=None):\n","    x = tf.keras.Sequential()\n","    for i in range(repetition):\n","        s = stride if i == 0 else 1\n","        x.add(tfc.SignalConv2D(\n","                filter_size,\n","                kernel_size,\n","                corr=True,\n","                strides_down=s,\n","                padding=\"same_zeros\",\n","                use_bias=True,\n","        ))\n","        if gdn_func:\n","            x.add(gdn_func)\n","        x.add(tf.keras.layers.PReLU(shared_axes=[1, 2]))\n","    return x\n","\n","\n","def build_vitblocks(repetition, num_heads, head_size, spatial_size, stride=1, gdn_func=None):\n","    x = tf.keras.Sequential()\n","    for i in range(repetition):\n","        s = stride if i == 0 else 1\n","        x.add(VitBlock(num_heads, head_size, spatial_size, stride=s))\n","        if gdn_func:\n","            x.add(gdn_func)\n","    return x\n","\n","\n","class SemViT_Encoder_Only(tf.keras.Model):\n","    def __init__(self, block_types, filters, num_blocks, has_gdn=True,\n","                 num_symbols=512):\n","        super().__init__()\n","        if has_gdn:\n","            gdn_func=tfc.layers.GDN()\n","            igdn_func=tfc.layers.GDN(inverse=True)\n","        else:\n","            gdn_func=tf.keras.layers.Lambda(lambda x: x)\n","            igdn_func=tf.keras.layers.Lambda(lambda x: x)\n","\n","        assert len(block_types) == len(filters) == len(num_blocks) == 6, \\\n","               \"length of block_types, filters, num_blocks should be 6\"\n","        self.encoder = SemViT_Encoder(\n","            block_types[:3],\n","            filters[:3],\n","            num_blocks[:3],\n","            num_symbols,\n","            gdn_func=gdn_func\n","        )\n","    \n","    def call(self, x):\n","        x = self.encoder(x)\n","\n","        return x\n","\n","\n","class SemViT_Decoder_Only(tf.keras.Model):\n","    def __init__(self, block_types, filters, num_blocks, has_gdn=True,\n","                 num_symbols=512):\n","        super().__init__()\n","        if has_gdn:\n","            gdn_func=tfc.layers.GDN()\n","            igdn_func=tfc.layers.GDN(inverse=True)\n","        else:\n","            gdn_func=tf.keras.layers.Lambda(lambda x: x)\n","            igdn_func=tf.keras.layers.Lambda(lambda x: x)\n","\n","        assert len(block_types) == len(filters) == len(num_blocks) == 6, \\\n","               \"length of block_types, filters, num_blocks should be 6\"\n","        self.decoder = SemViT_Decoder(\n","            block_types[3:],\n","            filters[3:],\n","            num_blocks[3:],\n","            gdn_func=igdn_func\n","        )\n","    \n","    def call(self, x):\n","        x = self.decoder(x)\n","\n","        return x\n","    \n","\n","\n","\n","class AWGNChannel(tf.keras.layers.Layer):\n","    def __init__(self, snrdB=None):\n","        super().__init__()\n","        self.snr = 10 ** (snrdB / 10) # in dB\n","    \n","\n","    def call(self, x):\n","        '''\n","        x: inputs with shape (b, c, 2)\n","           where last dimension denotes in-phase and quadrature-phase elements, respectively.\n","        '''\n","        assert x.shape[2] == 2, \"input shape should be (b, c, 2), where last dimension denotes i and q, respectively\"\n","        assert len(x.shape) == 3, \"input shape should be (b, c, 2)\"\n","\n","        i = x[:,:,0]\n","        q = x[:,:,1]\n","\n","        # power normalization\n","        sig_power = tf.math.reduce_mean(i ** 2 + q ** 2)\n","        snr = self.snr\n","\n","        n = tf.random.normal(\n","            tf.shape(x),\n","            mean=0,\n","            stddev=tf.math.sqrt(sig_power/(2*snr))\n","        )\n","\n","        y = x + n\n","        return y\n","    \n","\n","    def get_config(self):\n","        config = super().get_config()\n","        return config\n","\n","\n","\n","class RayleighChannel(tf.keras.layers.Layer):\n","    def __init__(self, snrdB=None, clip_snrdB=5):\n","        super().__init__()\n","        self.snr = 10 ** (snrdB / 10) # in dB\n","        self.clip_snr = 10 ** (clip_snrdB / 10)\n","    \n","\n","    def call(self, x):\n","        '''\n","        x: inputs with shape (b, c, 2)\n","           where last dimension denotes in-phase and quadrature-phase elements, respectively.\n","        Assumes slow rayleigh fading, where h does not change for single batch data\n","\n","        We clip the coefficient h to generate short-term SNR between +-5 dB of given long-term SNR.\n","        '''\n","        assert x.shape[2] == 2, \"input shape should be (b, c, 2), where last dimension denotes i and q, respectively\"\n","        assert len(x.shape) == 3, \"input shape should be (b, c, 2)\"\n","        \n","        i = x[:,:,0]\n","        q = x[:,:,1]\n","\n","        # power normalization\n","        sig_power = tf.math.reduce_mean(i ** 2 + q ** 2)\n","        \n","        # batch-wise slow fading\n","        h = tf.random.normal(\n","            (1, 1, 2),\n","            mean=0,\n","            stddev=tf.math.sqrt(0.5)\n","        )\n","\n","        snr = self.snr\n","\n","        n = tf.random.normal(\n","            tf.shape(x),\n","            mean=0,\n","            stddev=tf.math.sqrt(sig_power/(2*snr))\n","        )\n","\n","        yhat = h * x + n\n","\n","        return yhat\n","    \n","\n","    def get_config(self):\n","        config = super().get_config()\n","        return config\n","\n","\n","\n","class RicianChannel(tf.keras.layers.Layer):\n","    def __init__(self, snrdB=None, k=2):\n","        super().__init__()\n","        self.snr = 10 ** (snrdB / 10) # in dB\n","        self.k = k\n","    \n","\n","    def call(self, x):\n","        '''\n","        x: inputs with shape (b, c, 2)\n","           where last dimension denotes in-phase and quadrature-phase elements, respectively.\n","        Assumes slow rayleigh fading (for NLOS part), where h does not change for single batch data\n","\n","        We clip the coefficient h to generate short-term SNR between +-5 dB of given long-term SNR.\n","        '''\n","        assert x.shape[2] == 2, \"input shape should be (b, c, 2), where last dimension denotes i and q, respectively\"\n","        assert len(x.shape) == 3, \"input shape should be (b, c, 2)\"\n","        \n","        i = x[:,:,0]\n","        q = x[:,:,1]\n","\n","        # power normalization\n","        sig_power = tf.math.reduce_mean(i ** 2 + q ** 2)\n","        \n","        # batch-wise slow fading\n","        h = tf.random.normal(\n","            (1, 1, 2),\n","            mean=0,\n","            stddev=tf.math.sqrt(0.5)\n","        )\n","\n","        snr = self.snr\n","\n","        n = tf.random.normal(\n","            tf.shape(x),\n","            mean=0,\n","            stddev=tf.math.sqrt(sig_power/(2*snr))\n","        )\n","\n","        k = self.k\n","\n","        yhat = tf.math.sqrt(1 / (1+k)) * h * x + tf.math.sqrt(k / (1+k)) * x + n\n","\n","        return yhat\n","    \n","    \n","\n","class MLP(tf.keras.layers.Layer):\n","    def __init__(self, out_features, expansion_coeff=4):\n","        super().__init__()\n","\n","        self.fc1 = tf.keras.layers.Dense(\n","            out_features * expansion_coeff\n","        )\n","        self.gelu = tf.nn.gelu\n","        self.fc2 = tf.keras.layers.Dense(\n","            out_features\n","        )\n","    \n","    def call(self, x):\n","        x = self.fc1(x)\n","        x = self.gelu(x)\n","        x = self.fc2(x)\n","        return x\n","\n","\n","class RelativeMHSA(tf.keras.layers.Layer):\n","    '''\n","    Implements multihead attention \n","    with Swin-like learnable 2d relative positional encoding\n","    '''\n","    def __init__(self, num_heads, dim_head, spatial_size):\n","        '''\n","        num_heads: the number of heads\n","        dim_head: channel dimensions per head\n","        spatial_size: height/width of the input\n","        query/key/value shape: (b, h, w, c) where h == w \n","        '''\n","        super().__init__()\n","\n","        assert num_heads != 0, \"num_heads should be nonzero\"\n","\n","        self.dim_head = dim_head\n","        self.num_heads = num_heads\n","\n","        self.qkv = tf.keras.layers.Conv2D(\n","            filters=dim_head * 3,\n","            kernel_size=1\n","        )\n","\n","        self.head_transform = tf.keras.layers.Conv2D(\n","            filters=dim_head*num_heads,\n","            kernel_size=1\n","        )\n","\n","        # build rel. pos parameter and bias index here\n","        h = spatial_size\n","        pos_emb_idx_horizontal = tf.tile(tf.constant(\n","            [range(i, i+h) for i in range(0, -h, -1)]),\n","            multiples=[h, h]\n","        )\n","\n","        pos_emb_idx_vertical = tf.repeat(\n","            tf.repeat(\n","                tf.constant([range(i, i+h)\n","                             for i in range(0, -h, -1)]),\n","                repeats=h,\n","                axis=0\n","            ),\n","            repeats=h,\n","            axis=-1\n","        )\n","\n","        pos_emb_idx = (2*h-1) * (pos_emb_idx_vertical + h - 1) + \\\n","                      (pos_emb_idx_horizontal + h - 1)\n","\n","        self.pos_emb_idx = pos_emb_idx\n","\n","        initializer = tf.keras.initializers.GlorotNormal()\n","        self.learned_pos_emb = tf.Variable(\n","            initializer(shape=((2*h-1)**2,))\n","        )\n","\n","\n","    def call(self, x):\n","        b, h, w, c = x.shape\n","        m = self.num_heads\n","\n","        assert c % m == 0, \"channel dimension should be divisible \" \\\n","               f\"with number of heads, but c={c} and m={m} found\"\n","        d_h = c//m\n","\n","        # [b, h, w, c] to [b, m, h, w, c//m]\n","        x = tf.reshape(x, (-1, h, w, m, d_h))\n","        x = tf.transpose(x, (0, 3, 1, 2, 4))\n","\n","        x = self.qkv(x)\n","        x = tf.reshape(x, (-1, h*w, self.dim_head, 3))\n","        q = x[:, :, :, 0]\n","        k = x[:, :, :, 1]\n","        v = x[:, :, :, 2]\n","\n","        # normalize with sqrt(d)\n","        q = q / tf.sqrt(tf.constant(self.dim_head, tf.float32))\n","\n","        # attention map computation; q, k: (b*m, h*w, d_h)\n","        att_map = tf.einsum('bic,bjc->bij', q, k)\n","\n","        # add rel. pos. encoding to attention map\n","        pos_emb = tf.gather(self.learned_pos_emb, self.pos_emb_idx)\n","\n","        att_map = att_map + pos_emb\n","        att_map = tf.nn.softmax(att_map)\n","        \n","        v = tf.reshape(v, (-1, h*w, self.dim_head))\n","        v = tf.einsum('bij,bjc->bic', att_map, v)\n","\n","        # [b, m, h, w, c//m] to [b, h, w, c]\n","        v = tf.reshape(v, (-1, m, h, w, c//m))\n","        v = tf.transpose(v, (0, 2, 3, 1, 4))\n","        v = tf.reshape(v, (-1, h, w, c))\n","\n","        v = self.head_transform(v)\n","        return v\n","\n","\n","class VitBlock(tf.keras.layers.Layer):\n","    def __init__(self, num_heads, head_size,\n","                 spatial_size, stride=1):\n","        '''\n","        num_heads: the number of heads\n","        head_size: channel dimensions per head\n","        spatial_size: height/width of the input\n","                      (before downsampling)\n","        patchmerge: (boolean) 1/2 downsampling before MHSA\n","        '''\n","        super().__init__()\n","\n","        d_out = num_heads * head_size\n","        self.ln1 = tf.keras.layers.LayerNormalization()\n","\n","        self.patchmerge = tf.keras.layers.Conv2D(\n","            filters=d_out,\n","            kernel_size=stride,\n","            strides=stride,\n","        )\n","        spatial_size //= stride\n","\n","        self.mhsa = RelativeMHSA(\n","            num_heads=num_heads,\n","            dim_head=head_size,\n","            spatial_size=spatial_size\n","        )\n","\n","        self.ln2 = tf.keras.layers.LayerNormalization()\n","        self.mlp = MLP(d_out)\n","\n","    def call(self, x):\n","        x = self.patchmerge(x)\n","        x = self.ln1(x)\n","        x_residual = x\n","\n","        x = self.mhsa(x) \n","        x = tf.add(x, x_residual)\n","        \n","        x_residual = x\n","        x = self.ln2(x)\n","        x = self.mlp(x)\n","        x = tf.add(x, x_residual)\n","\n","        return x\n","\n","\n","\n","\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n","\n","\n","\n","\n","\n","def prepare_dataset():\n","  AUTO = tf.data.experimental.AUTOTUNE\n","  test_ds = dataset_generator('/kaggle/input/cifar10-pngs-in-folders/cifar10/test/')           #Give the correct paths\n","  train_ds = dataset_generator('/kaggle/input/cifar10-pngs-in-folders/cifar10/train/').cache()\n","\n","  normalize = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n","  augment_layer = tf.keras.Sequential([\n","        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n","        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","    ])\n","\n","  def normalize_and_augment(image, training):\n","    image = augment_layer(image, training=training)\n","    return image\n","\n","  train_ds = (\n","    train_ds.shuffle(50000, reshuffle_each_iteration=True)\n","            .map(lambda x, y: (normalize_and_augment(x, training=True), y), num_parallel_calls=AUTO)\n","            .map(lambda x, _: (x, x))\n","            .prefetch(AUTO)\n","  )\n","  test_ds = (\n","    test_ds.map(lambda x, y: (normalize(x), y))\n","           .map(lambda x, _: (x, x))\n","           .cache()\n","           .prefetch(AUTO)\n","  )\n","\n","  return train_ds, test_ds\n","\n","def main(config):\n","    if config['gpu']:\n","        os.environ[\"CUDA_VISIBLE_DEVICES\"] = config['gpu']\n","\n","    # Load CIFAR-10 dataset\n","    train_ds, test_ds = prepare_dataset()\n","\n","    EXPERIMENT_NAME = config['experiment_name']\n","    print(f'Running {EXPERIMENT_NAME}')\n","\n","    model = SemViT(\n","        config['block_types'],\n","        config['filters'],\n","        config['repetitions'],\n","        has_gdn=config['gdn'],\n","        num_symbols=config['data_size'],\n","        snrdB=config['train_snrdB'],\n","        channel=config['channel_types']\n","    )\n","\n","    def psnr(y_true, y_pred):\n","        return tf.image.psnr(y_true, y_pred, max_val=1)\n","\n","    model.compile(\n","        loss='mse',\n","        optimizer=tf.keras.optimizers.legacy.Adam(\n","            learning_rate=1e-4\n","        ),\n","        metrics=[\n","            psnr\n","        ]\n","    )\n","\n","    model.build(input_shape=(None, 32, 32, 3))\n","    model.summary()\n","\n","    if config['ckpt'] is not None:\n","        model.load_weights(config['ckpt'])\n","\n","    save_ckpt = [\n","        tf.keras.callbacks.ModelCheckpoint(\n","            filepath=f\"./ckpt/{EXPERIMENT_NAME}_\" + f\"{config['epochs']}\",\n","            save_best_only=True,\n","            monitor=\"val_loss\",\n","            save_weights_only=True,\n","            options=tf.train.CheckpointOptions(\n","                experimental_io_device=None, experimental_enable_async_checkpoint=True\n","            )\n","        )\n","    ]\n","\n","    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'logs/{EXPERIMENT_NAME}')\n","    history = model.fit(\n","        train_ds,\n","        initial_epoch=config['initial_epoch'],\n","        epochs=config['epochs'],\n","        callbacks=[tensorboard, save_ckpt],\n","        validation_data=test_ds,\n","    )\n","\n","    model.save_weights(f\"{EXPERIMENT_NAME}_\" + f\"{config['epochs']}\")\n","\n","# Run the main function with the config dictionary\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-16T14:49:57.157610Z","iopub.status.busy":"2024-08-16T14:49:57.157221Z","iopub.status.idle":"2024-08-16T14:49:57.164943Z","shell.execute_reply":"2024-08-16T14:49:57.163740Z","shell.execute_reply.started":"2024-08-16T14:49:57.157582Z"},"trusted":true},"outputs":[],"source":["config = {\n","    'data_size': 512,\n","    'channel_types': 'AWGN',\n","    'train_snrdB': 10,\n","    'block_types': 'CCVVCC',\n","    'experiment_name': 'experiment_1',\n","    'epochs': 10,\n","    'filters': [256, 256, 256, 256, 256, 256],\n","    'repetitions': [1, 1, 3, 3, 1, 1],\n","    'gdn': False,\n","    'initial_epoch': 0,\n","    'ckpt': None,\n","    'gpu': '0'\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-16T14:49:59.916941Z","iopub.status.busy":"2024-08-16T14:49:59.916516Z"},"trusted":true},"outputs":[],"source":["main(config)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":118250,"sourceId":283795,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
